{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the folder containing the txt files\n",
    "folder_path = os.path.join('src', 'data', 'ecb-speeches')\n",
    "\n",
    "# List all txt files in the folder\n",
    "txt_files = [f for f in os.listdir(folder_path) if f.endswith('.txt')]\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "df_speeches = pd.DataFrame(columns=['date', 'content'])\n",
    "\n",
    "# Iterate through the txt files and read their content\n",
    "for txt_file in txt_files:\n",
    "    # Extract the date from the file name\n",
    "    date_str = txt_file.split('_')[0]\n",
    "    date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "    \n",
    "    # Read the content of the file\n",
    "    with open(os.path.join(folder_path, txt_file), 'r') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    # Append the date and content to the DataFrame\n",
    "    df_speeches = pd.concat([df_speeches, pd.DataFrame({'date': [date], 'content': [content]})], ignore_index=True)\n",
    "\n",
    "# Sort the DataFrame by date\n",
    "df_speeches = df_speeches.sort_values(by='date').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_lines(df):\n",
    "    \"\"\"\n",
    "    Consolidate lines in the content of a dataframe. \n",
    "    If a line does not end with a full stop, it is merged \n",
    "    with the next line, removing unnecessary newline characters.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): Dataframe with 'content' column\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: Modified dataframe with consolidated lines\n",
    "    \"\"\"\n",
    "    consolidated_data = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        content = row['content']\n",
    "        lines = content.split('\\n')\n",
    "        consolidated_content = \"\"\n",
    "        for i, line in enumerate(lines):\n",
    "            line = line.strip()\n",
    "            if line and (line[-1] in \".!?\" or i == len(lines) - 1):\n",
    "                consolidated_content += line + \" \"\n",
    "            else:\n",
    "                consolidated_content += line\n",
    "\n",
    "        consolidated_row = row.copy()\n",
    "        consolidated_row['content'] = consolidated_content.strip()\n",
    "        consolidated_data.append(consolidated_row)\n",
    "\n",
    "    # Create new dataframe with consolidated content\n",
    "    new_df = pd.DataFrame(consolidated_data)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def split_paragraphs(df):\n",
    "    \"\"\"\n",
    "    Splits content of dataframe into separate rows. \n",
    "    If a paragraph exceeds 512 words, it is limited to \n",
    "    two nearly equal parts, with the split done at a full stop.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): Dataframe with 'date' and 'content' columns\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: Modified dataframe with split content\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        date = row['date']\n",
    "        content = row['content']\n",
    "\n",
    "        # Split content into sentences\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', content)\n",
    "\n",
    "        # Process each sentence\n",
    "        current_part = \"\"\n",
    "        for sentence in sentences:\n",
    "            if len(current_part.split()) + len(sentence.split()) <= 50:\n",
    "                current_part += \" \" + sentence\n",
    "            else:\n",
    "                if current_part.strip():\n",
    "                    data.append([date, current_part.strip()])\n",
    "                current_part = sentence\n",
    "\n",
    "        # Append remaining part if exists\n",
    "        if current_part.strip():\n",
    "            data.append([date, current_part.strip()])\n",
    "\n",
    "    # Create new dataframe\n",
    "    new_df = pd.DataFrame(data, columns=['date', 'content'])\n",
    "\n",
    "    return new_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>Mr. Duisenberg reports on the outcome of the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>The general picture is one of continued econom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>As far as pricedevelopments are concerned, inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>Economic growth has been driven increasingly b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>The favourable conjunctural situation has star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147049</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>Based on its experience, the ECB would strongl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147050</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>Also, considering the strict, risk-based natur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147051</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>The most prominent element of the ECB opinions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147052</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>While the proposed limit of €10,000 euro does ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147053</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>Let me now hand over to my colleagues who will...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147054 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date                                            content\n",
       "0      1998-07-17  Mr. Duisenberg reports on the outcome of the s...\n",
       "1      1998-07-17  The general picture is one of continued econom...\n",
       "2      1998-07-17  As far as pricedevelopments are concerned, inf...\n",
       "3      1998-07-17  Economic growth has been driven increasingly b...\n",
       "4      1998-07-17  The favourable conjunctural situation has star...\n",
       "...           ...                                                ...\n",
       "147049 2022-02-25  Based on its experience, the ECB would strongl...\n",
       "147050 2022-02-25  Also, considering the strict, risk-based natur...\n",
       "147051 2022-02-25  The most prominent element of the ECB opinions...\n",
       "147052 2022-02-25  While the proposed limit of €10,000 euro does ...\n",
       "147053 2022-02-25  Let me now hand over to my colleagues who will...\n",
       "\n",
       "[147054 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_speeches_consolidated = consolidate_lines(df_speeches)\n",
    "df_speeches_consolidated = split_paragraphs(df_speeches_consolidated)\n",
    "df_speeches_consolidated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create counts column that counts words in content column of each row\n",
    "df_speeches_consolidated['counts'] = df_speeches_consolidated['content'].str.split().str.len()\n",
    "\n",
    "# remove observations with missing values and counts of less than 50\n",
    "df_speeches_consolidated = df_speeches_consolidated[(df_speeches_consolidated['counts']>=20) & (df_speeches_consolidated['counts']<200) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Define the tokenizer\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ozodbek/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from transformers import pipeline\n",
    "\n",
    "import transformers\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    tokenizer=\"distilbert-base-uncased\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content  positive  negative\n",
      "0  Mr. Duisenberg reports on the outcome of the s...  0.988099  0.011901\n",
      "1  The general picture is one of continued econom...  0.960844  0.039156\n",
      "2  As far as pricedevelopments are concerned, inf...  0.997458  0.002542\n",
      "3  Economic growth has been driven increasingly b...  0.787363  0.212637\n",
      "4  The favourable conjunctural situation has star...  0.815906  0.184094\n",
      "5  As regards monetary and financial developments...  0.687710  0.312290\n",
      "6  In principle, the economic performance I have ...  0.531834  0.468166\n",
      "7  In this respect, I should like to underline th...  0.998245  0.001755\n",
      "8  Second, most Member States need togo a step fu...  0.928188  0.071812\n",
      "9  This implies that the benchmark for fiscalpoli...  0.995707  0.004293\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from functions import calculate_sentiment_distilbert\n",
    "\n",
    "max_chunk_length = 512\n",
    "\n",
    "# Create an empty DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# add content\n",
    "df['content'] = df_speeches_consolidated['content'].head(10)\n",
    "\n",
    "# Apply the sentiment analysis function to the 'content' column for the first 10 rows\n",
    "df[['positive', 'negative']] = df_speeches_consolidated['content'].head(10).apply(\n",
    "    lambda x: pd.Series(calculate_sentiment_distilbert(x))\n",
    ")\n",
    "# Print the updated DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date                                            content  positive  \\\n",
      "544 2008-09-03  Gertrude Tumpel-Gugerell: Start of the ECB/ESC...  0.983223   \n",
      "545 2008-09-04  Gertrude Tumpel-Gugerell: Moving ahead with th...  0.976558   \n",
      "546 2008-09-09  European Central Bank: Press conference – intr...  0.903439   \n",
      "547 2008-09-09  Jürgen Stark: Monetary policy during the finan...  0.945200   \n",
      "548 2008-09-09  Jean-Claude Trichet: Risk and the macro-econom...  0.931020   \n",
      "549 2008-09-09  José Manuel González-Páramo: Globalisation, ma...  0.932746   \n",
      "550 2008-09-10  Jürgen Stark: Economic perspectives and moneta...  0.931714   \n",
      "551 2008-09-10  Gertrude Tumpel-Gugerell: What is the role of ...  0.976124   \n",
      "552 2008-09-11  José Manuel González-Páramo: Some lessons from...  0.939504   \n",
      "553 2008-09-11  Jean Claude-Trichet: Hearing before the Econom...  0.889569   \n",
      "554 2008-09-11  Gertrude Tumpel-Gugerell: SEPA for cards\\nSpee...  0.900189   \n",
      "555 2008-09-15  Gertrude Tumpel-Gugerell: EU priorities for in...  0.954767   \n",
      "556 2008-09-15  Jean-Claude Trichet: The European Regulatory a...  0.946417   \n",
      "557 2008-09-17  Jean-Claude Trichet: Ehrenplaquette of the cit...  0.943632   \n",
      "558 2008-09-17  Gertrude Tumpel-Gugerell: Priorities for EU in...  0.906066   \n",
      "559 2008-09-17  Lucas Papademos: China and the European Union ...  0.964078   \n",
      "560 2008-09-23  Jean-Claude Trichet: Inauguration of the “Euro...  0.992300   \n",
      "561 2008-09-24  Jean-Claude Trichet: The entry of Slovakia int...  0.945500   \n",
      "562 2008-09-25  Jean-Claude Trichet: Interview with Hospodársk...  0.880834   \n",
      "563 2008-09-30  Lorenzo Bini Smaghi: Celebrating 50 years of E...  0.961880   \n",
      "564 2008-09-30  José Manuel González-Páramo: Central banks and...  0.926179   \n",
      "\n",
      "     negative  \n",
      "544  0.016777  \n",
      "545  0.023442  \n",
      "546  0.096561  \n",
      "547  0.054800  \n",
      "548  0.068980  \n",
      "549  0.067254  \n",
      "550  0.068286  \n",
      "551  0.023876  \n",
      "552  0.060496  \n",
      "553  0.110431  \n",
      "554  0.099811  \n",
      "555  0.045233  \n",
      "556  0.053583  \n",
      "557  0.056368  \n",
      "558  0.093934  \n",
      "559  0.035922  \n",
      "560  0.007700  \n",
      "561  0.054500  \n",
      "562  0.119166  \n",
      "563  0.038120  \n",
      "564  0.073821  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13265/2830050635.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df[['positive', 'negative']] = subset_df['content'].apply(lambda x: pd.Series(calculate_sentiment_distilbert(x)))\n",
      "/tmp/ipykernel_13265/2830050635.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df[['positive', 'negative']] = subset_df['content'].apply(lambda x: pd.Series(calculate_sentiment_distilbert(x)))\n"
     ]
    }
   ],
   "source": [
    "# Define the start and end dates of the desired date range\n",
    "start_date = '2008-09-01'\n",
    "end_date = '2008-09-30'\n",
    "\n",
    "# Filter the DataFrame based on the date range\n",
    "subset_df = df_speeches[(df_speeches['date'] >= start_date) & (df_speeches['date'] <= end_date)]\n",
    "\n",
    "# Apply the sentiment analysis function to the 'content' column for the subset\n",
    "subset_df[['positive', 'negative']] = subset_df['content'].apply(lambda x: pd.Series(calculate_sentiment_distilbert(x)))\n",
    "\n",
    "# Print the updated subset DataFrame\n",
    "print(subset_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speeches with FinBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('ProsusAI/finbert')\n",
    "model = BertForSequenceClassification.from_pretrained('ProsusAI/finbert')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import split_text\n",
    "from functions import calculate_sentiment_finbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13265/1113428978.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset[['positive', 'negative']] = subset['content'].head(10).apply(lambda x: pd.Series(calculate_sentiment_finbert(x)))\n",
      "/tmp/ipykernel_13265/1113428978.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset[['positive', 'negative']] = subset['content'].head(10).apply(lambda x: pd.Series(calculate_sentiment_finbert(x)))\n",
      "/tmp/ipykernel_13265/1113428978.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset['neutral'] = 1 - subset['positive'] - subset['negative']\n"
     ]
    }
   ],
   "source": [
    "# Apply the sentiment analysis function to the 'content' column for the first N rows\n",
    "\n",
    "N=2\n",
    "subset = df_speeches_consolidated.head(10)\n",
    "subset[['positive', 'negative']] = subset['content'].head(10).apply(lambda x: pd.Series(calculate_sentiment_finbert(x)))\n",
    "\n",
    "# Optional: Calculate the neutral sentiment as the remaining probability\n",
    "subset['neutral'] = 1 - subset['positive'] - subset['negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>counts</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>Mr. Duisenberg reports on the outcome of the s...</td>\n",
       "      <td>50</td>\n",
       "      <td>0.937748</td>\n",
       "      <td>0.041710</td>\n",
       "      <td>0.020542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>The general picture is one of continued econom...</td>\n",
       "      <td>34</td>\n",
       "      <td>0.034190</td>\n",
       "      <td>0.034694</td>\n",
       "      <td>0.931116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>As far as pricedevelopments are concerned, inf...</td>\n",
       "      <td>49</td>\n",
       "      <td>0.030530</td>\n",
       "      <td>0.951551</td>\n",
       "      <td>0.017919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>Economic growth has been driven increasingly b...</td>\n",
       "      <td>35</td>\n",
       "      <td>0.883557</td>\n",
       "      <td>0.097784</td>\n",
       "      <td>0.018659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>The favourable conjunctural situation has star...</td>\n",
       "      <td>49</td>\n",
       "      <td>0.101933</td>\n",
       "      <td>0.880079</td>\n",
       "      <td>0.017988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>As regards monetary and financial developments...</td>\n",
       "      <td>49</td>\n",
       "      <td>0.447888</td>\n",
       "      <td>0.532956</td>\n",
       "      <td>0.019157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>In principle, the economic performance I have ...</td>\n",
       "      <td>45</td>\n",
       "      <td>0.489348</td>\n",
       "      <td>0.406243</td>\n",
       "      <td>0.104409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>In this respect, I should like to underline th...</td>\n",
       "      <td>34</td>\n",
       "      <td>0.719490</td>\n",
       "      <td>0.179986</td>\n",
       "      <td>0.100524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>Second, most Member States need togo a step fu...</td>\n",
       "      <td>29</td>\n",
       "      <td>0.036569</td>\n",
       "      <td>0.946498</td>\n",
       "      <td>0.016933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1998-07-17</td>\n",
       "      <td>This implies that the benchmark for fiscalpoli...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.324513</td>\n",
       "      <td>0.065784</td>\n",
       "      <td>0.609703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                                            content  counts  \\\n",
       "0 1998-07-17  Mr. Duisenberg reports on the outcome of the s...      50   \n",
       "1 1998-07-17  The general picture is one of continued econom...      34   \n",
       "2 1998-07-17  As far as pricedevelopments are concerned, inf...      49   \n",
       "3 1998-07-17  Economic growth has been driven increasingly b...      35   \n",
       "4 1998-07-17  The favourable conjunctural situation has star...      49   \n",
       "5 1998-07-17  As regards monetary and financial developments...      49   \n",
       "6 1998-07-17  In principle, the economic performance I have ...      45   \n",
       "7 1998-07-17  In this respect, I should like to underline th...      34   \n",
       "8 1998-07-17  Second, most Member States need togo a step fu...      29   \n",
       "9 1998-07-17  This implies that the benchmark for fiscalpoli...      30   \n",
       "\n",
       "   positive  negative   neutral  \n",
       "0  0.937748  0.041710  0.020542  \n",
       "1  0.034190  0.034694  0.931116  \n",
       "2  0.030530  0.951551  0.017919  \n",
       "3  0.883557  0.097784  0.018659  \n",
       "4  0.101933  0.880079  0.017988  \n",
       "5  0.447888  0.532956  0.019157  \n",
       "6  0.489348  0.406243  0.104409  \n",
       "7  0.719490  0.179986  0.100524  \n",
       "8  0.036569  0.946498  0.016933  \n",
       "9  0.324513  0.065784  0.609703  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting with press releases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting with press releases\n",
    "import pandas as pd\n",
    "press_releases = pd.read_csv(\"src/data/ecb_releases_302.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-08-2023</td>\n",
       "      <td>10 August 2023 Europa Open Air 2023 celebrates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05-07-2023</td>\n",
       "      <td>5 July 2023 Compared with April 2023: consumer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04-07-2023</td>\n",
       "      <td>4 July 2023 Credit terms and conditions tighte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28-06-2023</td>\n",
       "      <td>28 June 2023 Proposed legislation establishes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22-06-2023</td>\n",
       "      <td>22 June 2023 The aggregate of total assets of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>18-09-1998</td>\n",
       "      <td>The European Central Bank (ECB) will today pub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>18-09-1998</td>\n",
       "      <td>The Headquarters Agreement between the Governm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>12-09-1998</td>\n",
       "      <td>In accordance with the Resolution adopted by t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>12-09-1998</td>\n",
       "      <td>Given that the euro banknotes will be put into...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>12-09-1998</td>\n",
       "      <td>In addition to its meetings scheduled for 13 O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                                            content\n",
       "0    10-08-2023  10 August 2023 Europa Open Air 2023 celebrates...\n",
       "1    05-07-2023  5 July 2023 Compared with April 2023: consumer...\n",
       "2    04-07-2023  4 July 2023 Credit terms and conditions tighte...\n",
       "3    28-06-2023  28 June 2023 Proposed legislation establishes ...\n",
       "4    22-06-2023  22 June 2023 The aggregate of total assets of ...\n",
       "..          ...                                                ...\n",
       "297  18-09-1998  The European Central Bank (ECB) will today pub...\n",
       "298  18-09-1998  The Headquarters Agreement between the Governm...\n",
       "299  12-09-1998  In accordance with the Resolution adopted by t...\n",
       "300  12-09-1998  Given that the euro banknotes will be put into...\n",
       "301  12-09-1998  In addition to its meetings scheduled for 13 O...\n",
       "\n",
       "[302 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Convert date column to datetime format\n",
    "press_releases['date'] = pd.to_datetime(press_releases['date'], format='%d %B %Y')\n",
    "\n",
    "# Convert date to \"DD-MM-YYYY\" format\n",
    "press_releases['date'] = press_releases['date'].dt.strftime('%d-%m-%Y')\n",
    "\n",
    "# Remove new line characters, replace with space\n",
    "press_releases['content'] = press_releases['content'].str.replace('\\n', ' ')\n",
    "\n",
    "press_releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-08-2023</td>\n",
       "      <td>10 August 2023 Europa Open Air 2023 celebrates...</td>\n",
       "      <td>0.990885</td>\n",
       "      <td>0.009115</td>\n",
       "      <td>0.013838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05-07-2023</td>\n",
       "      <td>5 July 2023 Compared with April 2023: consumer...</td>\n",
       "      <td>0.985537</td>\n",
       "      <td>0.014463</td>\n",
       "      <td>0.581922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04-07-2023</td>\n",
       "      <td>4 July 2023 Credit terms and conditions tighte...</td>\n",
       "      <td>0.936402</td>\n",
       "      <td>0.063598</td>\n",
       "      <td>0.588270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28-06-2023</td>\n",
       "      <td>28 June 2023 Proposed legislation establishes ...</td>\n",
       "      <td>0.922678</td>\n",
       "      <td>0.077322</td>\n",
       "      <td>0.011897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22-06-2023</td>\n",
       "      <td>22 June 2023 The aggregate of total assets of ...</td>\n",
       "      <td>0.975960</td>\n",
       "      <td>0.024040</td>\n",
       "      <td>0.212809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>18-09-1998</td>\n",
       "      <td>The European Central Bank (ECB) will today pub...</td>\n",
       "      <td>0.988458</td>\n",
       "      <td>0.011542</td>\n",
       "      <td>0.021108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>18-09-1998</td>\n",
       "      <td>The Headquarters Agreement between the Governm...</td>\n",
       "      <td>0.976587</td>\n",
       "      <td>0.023413</td>\n",
       "      <td>0.012490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>12-09-1998</td>\n",
       "      <td>In accordance with the Resolution adopted by t...</td>\n",
       "      <td>0.956106</td>\n",
       "      <td>0.043894</td>\n",
       "      <td>0.020652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>12-09-1998</td>\n",
       "      <td>Given that the euro banknotes will be put into...</td>\n",
       "      <td>0.883076</td>\n",
       "      <td>0.116924</td>\n",
       "      <td>0.028728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>12-09-1998</td>\n",
       "      <td>In addition to its meetings scheduled for 13 O...</td>\n",
       "      <td>0.715475</td>\n",
       "      <td>0.284525</td>\n",
       "      <td>0.049911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                                            content  positive  \\\n",
       "0    10-08-2023  10 August 2023 Europa Open Air 2023 celebrates...  0.990885   \n",
       "1    05-07-2023  5 July 2023 Compared with April 2023: consumer...  0.985537   \n",
       "2    04-07-2023  4 July 2023 Credit terms and conditions tighte...  0.936402   \n",
       "3    28-06-2023  28 June 2023 Proposed legislation establishes ...  0.922678   \n",
       "4    22-06-2023  22 June 2023 The aggregate of total assets of ...  0.975960   \n",
       "..          ...                                                ...       ...   \n",
       "297  18-09-1998  The European Central Bank (ECB) will today pub...  0.988458   \n",
       "298  18-09-1998  The Headquarters Agreement between the Governm...  0.976587   \n",
       "299  12-09-1998  In accordance with the Resolution adopted by t...  0.956106   \n",
       "300  12-09-1998  Given that the euro banknotes will be put into...  0.883076   \n",
       "301  12-09-1998  In addition to its meetings scheduled for 13 O...  0.715475   \n",
       "\n",
       "     negative   neutral  \n",
       "0    0.009115  0.013838  \n",
       "1    0.014463  0.581922  \n",
       "2    0.063598  0.588270  \n",
       "3    0.077322  0.011897  \n",
       "4    0.024040  0.212809  \n",
       "..        ...       ...  \n",
       "297  0.011542  0.021108  \n",
       "298  0.023413  0.012490  \n",
       "299  0.043894  0.020652  \n",
       "300  0.116924  0.028728  \n",
       "301  0.284525  0.049911  \n",
       "\n",
       "[302 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# press releases with distilbert\n",
    "\n",
    "# Apply the sentiment analysis function to the 'content' column for the subset\n",
    "press_releases[['positive', 'negative']] = press_releases['content'].apply(lambda x: pd.Series(calculate_sentiment_distilbert(x)))\n",
    "press_releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "# Load the tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('ProsusAI/finbert')\n",
    "model = BertForSequenceClassification.from_pretrained('ProsusAI/finbert')\n",
    "\n",
    "from functions import split_text\n",
    "from functions import calculate_sentiment_finbert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# NO NEED TO RUN FOR NOW, IT\\'S BEEN SAVED AND WILL BE IMPORTED IN THE NEXT STEP\\n\\nsubset = press_releases\\nsubset[[\\'positive\\', \\'negative\\']] = subset[\\'content\\'].apply(lambda x: pd.Series(calculate_sentiment_finbert(x)))\\n\\n# Optional: Calculate the neutral sentiment as the remaining probability\\nsubset[\\'neutral\\'] = 1 - subset[\\'positive\\'] - subset[\\'negative\\']\\n\\n# current time and date\\ncurrent_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\\n\\n# Define the filename with the current date and time\\nfilename = f\"src/output/finbert_sentiment_press_releases_{current_datetime}.csv\"\\n\\n# Save the DataFrame to the specified filename\\nsubset.to_csv(filename, index=False)\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# NO NEED TO RUN FOR NOW, IT'S BEEN SAVED AND WILL BE IMPORTED IN THE NEXT STEP\n",
    "\n",
    "subset = press_releases\n",
    "subset[['positive', 'negative']] = subset['content'].apply(lambda x: pd.Series(calculate_sentiment_finbert(x)))\n",
    "\n",
    "# Optional: Calculate the neutral sentiment as the remaining probability\n",
    "subset['neutral'] = 1 - subset['positive'] - subset['negative']\n",
    "\n",
    "# current time and date\n",
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Define the filename with the current date and time\n",
    "filename = f\"src/output/finbert_sentiment_press_releases_{current_datetime}.csv\"\n",
    "\n",
    "# Save the DataFrame to the specified filename\n",
    "subset.to_csv(filename, index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-08-2023</td>\n",
       "      <td>10 August 2023 Europa Open Air 2023 celebrates...</td>\n",
       "      <td>0.877308</td>\n",
       "      <td>0.108855</td>\n",
       "      <td>0.013838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05-07-2023</td>\n",
       "      <td>5 July 2023 Compared with April 2023: consumer...</td>\n",
       "      <td>0.338591</td>\n",
       "      <td>0.079486</td>\n",
       "      <td>0.581922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04-07-2023</td>\n",
       "      <td>4 July 2023 Credit terms and conditions tighte...</td>\n",
       "      <td>0.221073</td>\n",
       "      <td>0.190657</td>\n",
       "      <td>0.588270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28-06-2023</td>\n",
       "      <td>28 June 2023 Proposed legislation establishes ...</td>\n",
       "      <td>0.723583</td>\n",
       "      <td>0.264521</td>\n",
       "      <td>0.011897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22-06-2023</td>\n",
       "      <td>22 June 2023 The aggregate of total assets of ...</td>\n",
       "      <td>0.677040</td>\n",
       "      <td>0.110151</td>\n",
       "      <td>0.212809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>18-09-1998</td>\n",
       "      <td>The European Central Bank (ECB) will today pub...</td>\n",
       "      <td>0.946169</td>\n",
       "      <td>0.032723</td>\n",
       "      <td>0.021108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>18-09-1998</td>\n",
       "      <td>The Headquarters Agreement between the Governm...</td>\n",
       "      <td>0.738816</td>\n",
       "      <td>0.248694</td>\n",
       "      <td>0.012490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>12-09-1998</td>\n",
       "      <td>In accordance with the Resolution adopted by t...</td>\n",
       "      <td>0.877338</td>\n",
       "      <td>0.102010</td>\n",
       "      <td>0.020652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>12-09-1998</td>\n",
       "      <td>Given that the euro banknotes will be put into...</td>\n",
       "      <td>0.945670</td>\n",
       "      <td>0.025603</td>\n",
       "      <td>0.028728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>12-09-1998</td>\n",
       "      <td>In addition to its meetings scheduled for 13 O...</td>\n",
       "      <td>0.930709</td>\n",
       "      <td>0.019379</td>\n",
       "      <td>0.049911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                                            content  positive  \\\n",
       "0    10-08-2023  10 August 2023 Europa Open Air 2023 celebrates...  0.877308   \n",
       "1    05-07-2023  5 July 2023 Compared with April 2023: consumer...  0.338591   \n",
       "2    04-07-2023  4 July 2023 Credit terms and conditions tighte...  0.221073   \n",
       "3    28-06-2023  28 June 2023 Proposed legislation establishes ...  0.723583   \n",
       "4    22-06-2023  22 June 2023 The aggregate of total assets of ...  0.677040   \n",
       "..          ...                                                ...       ...   \n",
       "297  18-09-1998  The European Central Bank (ECB) will today pub...  0.946169   \n",
       "298  18-09-1998  The Headquarters Agreement between the Governm...  0.738816   \n",
       "299  12-09-1998  In accordance with the Resolution adopted by t...  0.877338   \n",
       "300  12-09-1998  Given that the euro banknotes will be put into...  0.945670   \n",
       "301  12-09-1998  In addition to its meetings scheduled for 13 O...  0.930709   \n",
       "\n",
       "     negative   neutral  \n",
       "0    0.108855  0.013838  \n",
       "1    0.079486  0.581922  \n",
       "2    0.190657  0.588270  \n",
       "3    0.264521  0.011897  \n",
       "4    0.110151  0.212809  \n",
       "..        ...       ...  \n",
       "297  0.032723  0.021108  \n",
       "298  0.248694  0.012490  \n",
       "299  0.102010  0.020652  \n",
       "300  0.025603  0.028728  \n",
       "301  0.019379  0.049911  \n",
       "\n",
       "[302 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the saved CSV file into a DataFrame\n",
    "\n",
    "press_releases = pd.read_csv(\"src/output/finbert_sentiment_press_releases_2023-08-22_13-22-32.csv\")\n",
    "press_releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock market data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date Symbol  Indexvalue  Date_merge day_of_week    month  delta_daily  \\\n",
      "0 1999-01-04   V2TX     18.2033  04-01-1999      Monday  January          NaN   \n",
      "1 1999-01-05   V2TX     29.6912  05-01-1999     Tuesday  January      11.4879   \n",
      "2 1999-01-06   V2TX     25.1670  06-01-1999   Wednesday  January      -4.5242   \n",
      "3 1999-01-07   V2TX     32.5205  07-01-1999    Thursday  January       7.3535   \n",
      "4 1999-01-08   V2TX     33.2296  08-01-1999      Friday  January       0.7091   \n",
      "\n",
      "   delta_3d  delta_5d  delta_30d  \n",
      "0       NaN       NaN        NaN  \n",
      "1       NaN       NaN        NaN  \n",
      "2       NaN       NaN        NaN  \n",
      "3   14.3172       NaN        NaN  \n",
      "4    3.5384       NaN        NaN  \n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to your data file\n",
    "data_path = \"src/data/stoxx.txt\"\n",
    "\n",
    "# Read the data file into a DataFrame\n",
    "vstoxx_df = pd.read_csv(data_path, delimiter=\";\", parse_dates=[\"Date\"], dayfirst=True)\n",
    "\n",
    "# Change the date format to DD-MM-YYYY\n",
    "vstoxx_df[\"Date_merge\"] = vstoxx_df[\"Date\"].dt.strftime(\"%d-%m-%Y\")\n",
    "\n",
    "# generate day of the week column\n",
    "vstoxx_df['day_of_week'] = pd.to_datetime(vstoxx_df['Date']).dt.day_name()\n",
    "\n",
    "# generate month column\n",
    "vstoxx_df['month'] = pd.to_datetime(vstoxx_df['Date']).dt.month_name()\n",
    "\n",
    "# calculate the daily change in the index\n",
    "vstoxx_df['delta_daily'] = vstoxx_df['Indexvalue'].diff()\n",
    "vstoxx_df['delta_3d'] = vstoxx_df['Indexvalue'].diff(3)\n",
    "vstoxx_df['delta_5d'] = vstoxx_df['Indexvalue'].diff(5)\n",
    "vstoxx_df['delta_30d'] = vstoxx_df['Indexvalue'].diff(30)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(vstoxx_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Indexvalue</th>\n",
       "      <th>Date_merge</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>delta_daily</th>\n",
       "      <th>delta_3d</th>\n",
       "      <th>delta_5d</th>\n",
       "      <th>delta_30d</th>\n",
       "      <th>date</th>\n",
       "      <th>Percentage_Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-01-04</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>18.2033</td>\n",
       "      <td>04-01-1999</td>\n",
       "      <td>Monday</td>\n",
       "      <td>January</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04-01-1999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999-01-05</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>29.6912</td>\n",
       "      <td>05-01-1999</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>January</td>\n",
       "      <td>11.4879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05-01-1999</td>\n",
       "      <td>0.631089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-01-05</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>29.6912</td>\n",
       "      <td>05-01-1999</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>January</td>\n",
       "      <td>11.4879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05-01-1999</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-01-06</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>25.1670</td>\n",
       "      <td>06-01-1999</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>January</td>\n",
       "      <td>-4.5242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.152375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999-01-07</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>32.5205</td>\n",
       "      <td>07-01-1999</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>January</td>\n",
       "      <td>7.3535</td>\n",
       "      <td>14.3172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07-01-1999</td>\n",
       "      <td>0.292188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6304</th>\n",
       "      <td>2023-08-15</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>18.8579</td>\n",
       "      <td>15-08-2023</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>August</td>\n",
       "      <td>0.8050</td>\n",
       "      <td>0.7815</td>\n",
       "      <td>-0.6814</td>\n",
       "      <td>4.7564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6305</th>\n",
       "      <td>2023-08-16</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>18.5510</td>\n",
       "      <td>16-08-2023</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>August</td>\n",
       "      <td>-0.3069</td>\n",
       "      <td>0.1764</td>\n",
       "      <td>-0.4286</td>\n",
       "      <td>3.2565</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.016274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6306</th>\n",
       "      <td>2023-08-17</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>20.3539</td>\n",
       "      <td>17-08-2023</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>August</td>\n",
       "      <td>1.8029</td>\n",
       "      <td>2.3010</td>\n",
       "      <td>2.2775</td>\n",
       "      <td>1.1262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.097186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6307</th>\n",
       "      <td>2023-08-18</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>20.2456</td>\n",
       "      <td>18-08-2023</td>\n",
       "      <td>Friday</td>\n",
       "      <td>August</td>\n",
       "      <td>-0.1083</td>\n",
       "      <td>1.3877</td>\n",
       "      <td>1.8710</td>\n",
       "      <td>2.7082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.005321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6308</th>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>V2TX</td>\n",
       "      <td>19.8367</td>\n",
       "      <td>21-08-2023</td>\n",
       "      <td>Monday</td>\n",
       "      <td>August</td>\n",
       "      <td>-0.4089</td>\n",
       "      <td>1.2857</td>\n",
       "      <td>1.7838</td>\n",
       "      <td>2.3326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.020197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6309 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date Symbol  Indexvalue  Date_merge day_of_week    month  \\\n",
       "0    1999-01-04   V2TX     18.2033  04-01-1999      Monday  January   \n",
       "1    1999-01-05   V2TX     29.6912  05-01-1999     Tuesday  January   \n",
       "2    1999-01-05   V2TX     29.6912  05-01-1999     Tuesday  January   \n",
       "3    1999-01-06   V2TX     25.1670  06-01-1999   Wednesday  January   \n",
       "4    1999-01-07   V2TX     32.5205  07-01-1999    Thursday  January   \n",
       "...         ...    ...         ...         ...         ...      ...   \n",
       "6304 2023-08-15   V2TX     18.8579  15-08-2023     Tuesday   August   \n",
       "6305 2023-08-16   V2TX     18.5510  16-08-2023   Wednesday   August   \n",
       "6306 2023-08-17   V2TX     20.3539  17-08-2023    Thursday   August   \n",
       "6307 2023-08-18   V2TX     20.2456  18-08-2023      Friday   August   \n",
       "6308 2023-08-21   V2TX     19.8367  21-08-2023      Monday   August   \n",
       "\n",
       "      delta_daily  delta_3d  delta_5d  delta_30d        date  \\\n",
       "0             NaN       NaN       NaN        NaN  04-01-1999   \n",
       "1         11.4879       NaN       NaN        NaN  05-01-1999   \n",
       "2         11.4879       NaN       NaN        NaN  05-01-1999   \n",
       "3         -4.5242       NaN       NaN        NaN         NaN   \n",
       "4          7.3535   14.3172       NaN        NaN  07-01-1999   \n",
       "...           ...       ...       ...        ...         ...   \n",
       "6304       0.8050    0.7815   -0.6814     4.7564         NaN   \n",
       "6305      -0.3069    0.1764   -0.4286     3.2565         NaN   \n",
       "6306       1.8029    2.3010    2.2775     1.1262         NaN   \n",
       "6307      -0.1083    1.3877    1.8710     2.7082         NaN   \n",
       "6308      -0.4089    1.2857    1.7838     2.3326         NaN   \n",
       "\n",
       "      Percentage_Change  \n",
       "0                   NaN  \n",
       "1              0.631089  \n",
       "2              0.000000  \n",
       "3             -0.152375  \n",
       "4              0.292188  \n",
       "...                 ...  \n",
       "6304           0.044591  \n",
       "6305          -0.016274  \n",
       "6306           0.097186  \n",
       "6307          -0.005321  \n",
       "6308          -0.020197  \n",
       "\n",
       "[6309 rows x 12 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the press release dates into the vstoxx_df DataFrame\n",
    "vstoxx_df = pd.merge(vstoxx_df, press_releases[['date']], how='left', left_on='Date_merge', right_on='date')\n",
    "\n",
    "# Calculate the percentage change in the index\n",
    "vstoxx_df['Percentage_Change'] = (vstoxx_df['Indexvalue'] - vstoxx_df['Indexvalue'].shift(1)) / vstoxx_df['Indexvalue'].shift(1)\n",
    "vstoxx_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13265/2410193295.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bond_data['b_delta_daily'] = bond_data['bond_price'].diff()\n",
      "/tmp/ipykernel_13265/2410193295.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bond_data['b_delta_3d'] = bond_data['bond_price'].diff(3)\n",
      "/tmp/ipykernel_13265/2410193295.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bond_data['b_delta_5d'] = bond_data['bond_price'].diff(5)\n",
      "/tmp/ipykernel_13265/2410193295.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bond_data['b_delta_30d'] = bond_data['bond_price'].diff(30)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>bond_price</th>\n",
       "      <th>b_delta_daily</th>\n",
       "      <th>b_delta_3d</th>\n",
       "      <th>b_delta_5d</th>\n",
       "      <th>b_delta_30d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-10-23</td>\n",
       "      <td>20.524277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-10-24</td>\n",
       "      <td>20.475508</td>\n",
       "      <td>-0.048769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-10-27</td>\n",
       "      <td>20.343830</td>\n",
       "      <td>-0.131678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-10-28</td>\n",
       "      <td>20.735615</td>\n",
       "      <td>0.391785</td>\n",
       "      <td>0.211338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-10-29</td>\n",
       "      <td>20.865675</td>\n",
       "      <td>0.130060</td>\n",
       "      <td>0.390167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>2023-07-25</td>\n",
       "      <td>30.100000</td>\n",
       "      <td>0.130001</td>\n",
       "      <td>-0.049999</td>\n",
       "      <td>-0.309999</td>\n",
       "      <td>1.268011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>2023-07-26</td>\n",
       "      <td>30.080000</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>-0.070000</td>\n",
       "      <td>-0.240000</td>\n",
       "      <td>0.866453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>2023-07-27</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>-0.080000</td>\n",
       "      <td>0.030001</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>0.590784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>2023-07-28</td>\n",
       "      <td>30.490000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.389999</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.982948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>30.410000</td>\n",
       "      <td>-0.080000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.440001</td>\n",
       "      <td>0.462690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2206 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  bond_price  b_delta_daily  b_delta_3d  b_delta_5d  \\\n",
       "0    2014-10-23   20.524277            NaN         NaN         NaN   \n",
       "1    2014-10-24   20.475508      -0.048769         NaN         NaN   \n",
       "2    2014-10-27   20.343830      -0.131678         NaN         NaN   \n",
       "3    2014-10-28   20.735615       0.391785    0.211338         NaN   \n",
       "4    2014-10-29   20.865675       0.130060    0.390167         NaN   \n",
       "...         ...         ...            ...         ...         ...   \n",
       "2201 2023-07-25   30.100000       0.130001   -0.049999   -0.309999   \n",
       "2202 2023-07-26   30.080000      -0.020000   -0.070000   -0.240000   \n",
       "2203 2023-07-27   30.000000      -0.080000    0.030001   -0.150000   \n",
       "2204 2023-07-28   30.490000       0.490000    0.389999    0.340000   \n",
       "2205 2023-07-31   30.410000      -0.080000    0.330000    0.440001   \n",
       "\n",
       "      b_delta_30d  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  \n",
       "...           ...  \n",
       "2201     1.268011  \n",
       "2202     0.866453  \n",
       "2203     0.590784  \n",
       "2204     0.982948  \n",
       "2205     0.462690  \n",
       "\n",
       "[2206 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bond prices\n",
    "\n",
    "# Define the ticker symbol for the Eurozone bond you're interested in\n",
    "bond_ticker = [\"\"]\n",
    "\n",
    "# Define the start and end dates for the data you want to fetch\n",
    "start_date = \"2000-01-01\"\n",
    "end_date = \"2023-08-01\"\n",
    "\n",
    "# Fetch the bond price data using yfinance\n",
    "bond_data = yf.download(bond_ticker, start=start_date, end=end_date)\n",
    "\n",
    "# remove the 1st row for Date, and keep it in 0th row\n",
    "bond_data.reset_index(inplace=True)\n",
    "\n",
    "# keep only date and adjusted close columns\n",
    "bond_data = bond_data[['Date','Adj Close']]\n",
    "bond_data.columns = ['Date', 'bond_price']\n",
    "\n",
    "# generate more variables\n",
    "bond_data['b_delta_daily'] = bond_data['bond_price'].diff()\n",
    "bond_data['b_delta_3d'] = bond_data['bond_price'].diff(3)\n",
    "bond_data['b_delta_5d'] = bond_data['bond_price'].diff(5)\n",
    "bond_data['b_delta_30d'] = bond_data['bond_price'].diff(30)\n",
    "\n",
    "# Display the downloaded data\n",
    "bond_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import FinBERT sentiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "finbert_releases = pd.read_csv(\"src/output/finbert_sentiment_press_releases_2023-08-22_13-22-32.csv\")\n",
    "finbert_releases\n",
    "\n",
    "# change the date format to YYYY-MM-DD\n",
    "finbert_releases['date'] = pd.to_datetime(finbert_releases['date'], format='%d-%m-%Y')\n",
    "\n",
    "# merge the finbert releases with the bond data\n",
    "finbert_releases = pd.merge(finbert_releases, bond_data, how='left', left_on='date', right_on='Date')\n",
    "\n",
    "# Merge the press release dates into the vstoxx_df DataFrame\n",
    "finbert_releases = pd.concat([finbert_releases, vstoxx_df[['Percentage_Change', 'delta_daily', 'delta_3d', 'delta_5d', 'delta_30d']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data with no nans\n",
    "restricted_sample = finbert_releases.dropna()\n",
    "restricted_sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
